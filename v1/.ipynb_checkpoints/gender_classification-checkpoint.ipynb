{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Aisha</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A'ishah</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Aa'isha</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aa'ishah</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Aaban</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Aabha</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Aabid</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Aabraham</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Aabriella</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Aachal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Gender  Score\n",
       "0      Aisha       0    0.0\n",
       "1    A'ishah       0    0.0\n",
       "2    Aa'isha       0    0.0\n",
       "3   Aa'ishah       0    0.0\n",
       "4      Aaban       1    1.0\n",
       "5      Aabha       0    1.0\n",
       "6      Aabid       1    1.0\n",
       "7   Aabraham       1    0.0\n",
       "8  Aabriella       0    1.0\n",
       "9     Aachal       0    0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_location = r'D:\\Datasets\\gender-names\\gender_refine-csv.csv'\n",
    "\n",
    "data = pd.read_csv(data_location)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length'] = data.apply(lambda row: len(row.Name), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if sys.path[0] == '':\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "      <th>no_of_vowels</th>\n",
       "      <th>percentage_of_vowels</th>\n",
       "      <th>ends_with_vowels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Aisha</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>A'ishah</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Aa'isha</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aa'ishah</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Aaban</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Aabha</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Aabid</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Aabraham</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Aabriella</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Aachal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Gender  Score  length  no_of_vowels  percentage_of_vowels  \\\n",
       "0      Aisha       0    0.0       5             3              0.600000   \n",
       "1    A'ishah       0    0.0       7             3              0.428571   \n",
       "2    Aa'isha       0    0.0       7             4              0.571429   \n",
       "3   Aa'ishah       0    0.0       8             4              0.500000   \n",
       "4      Aaban       1    1.0       5             3              0.600000   \n",
       "5      Aabha       0    1.0       5             3              0.600000   \n",
       "6      Aabid       1    1.0       5             3              0.600000   \n",
       "7   Aabraham       1    0.0       8             4              0.500000   \n",
       "8  Aabriella       0    1.0       9             5              0.555556   \n",
       "9     Aachal       0    0.0       6             3              0.500000   \n",
       "\n",
       "   ends_with_vowels  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 0  \n",
       "4                 0  \n",
       "5                 1  \n",
       "6                 0  \n",
       "7                 0  \n",
       "8                 1  \n",
       "9                 0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vowels = 'aeiou'\n",
    "data['no_of_vowels'] = 0\n",
    "data['percentage_of_vowels'] = 0.0\n",
    "data['ends_with_vowels'] = 0\n",
    "\n",
    "for i, names in enumerate(data['Name']):\n",
    "  count_vowels = 0\n",
    "  for alpha in names.lower():\n",
    "    if alpha in vowels:\n",
    "      count_vowels += 1\n",
    "  data['no_of_vowels'][i] = count_vowels\n",
    "  data['percentage_of_vowels'][i] = count_vowels/(len(names))\n",
    "  if names[len(names)-1] in vowels:\n",
    "    data['ends_with_vowels'][i] = 1\n",
    "  else:\n",
    "    data['ends_with_vowels'][i] = 0\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "maxLength = data['length'].max()\n",
    "print(maxLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for i, names in enumerate(data['Name']):\n",
    "  if \"�\" in names:\n",
    "    print(i, names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "D:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Score</th>\n",
       "      <th>length</th>\n",
       "      <th>no_of_vowels</th>\n",
       "      <th>percentage_of_vowels</th>\n",
       "      <th>ends_with_vowels</th>\n",
       "      <th>0st_character</th>\n",
       "      <th>1st_character</th>\n",
       "      <th>2st_character</th>\n",
       "      <th>3st_character</th>\n",
       "      <th>...</th>\n",
       "      <th>12st_character</th>\n",
       "      <th>13st_character</th>\n",
       "      <th>14st_character</th>\n",
       "      <th>15st_character</th>\n",
       "      <th>16st_character</th>\n",
       "      <th>17st_character</th>\n",
       "      <th>18st_character</th>\n",
       "      <th>19st_character</th>\n",
       "      <th>20st_character</th>\n",
       "      <th>21st_character</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Lylla</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>12</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Bess</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>-12</td>\n",
       "      <td>-9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Valissa</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>-13</td>\n",
       "      <td>-2</td>\n",
       "      <td>-5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Aldith</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>-13</td>\n",
       "      <td>-2</td>\n",
       "      <td>-10</td>\n",
       "      <td>-5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Ahzab</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>-13</td>\n",
       "      <td>-6</td>\n",
       "      <td>13</td>\n",
       "      <td>-13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Krisi</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1</td>\n",
       "      <td>-3</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Amerah</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>-13</td>\n",
       "      <td>-1</td>\n",
       "      <td>-9</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Mariellen</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-13</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Coriene</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>-5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Citalli</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5</td>\n",
       "      <td>7</td>\n",
       "      <td>-13</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name  Score  length  no_of_vowels  percentage_of_vowels  \\\n",
       "0      Lylla    1.0       5             1              0.200000   \n",
       "1       Bess    0.0       4             1              0.250000   \n",
       "2    Valissa    1.0       7             3              0.428571   \n",
       "3     Aldith    0.0       6             2              0.333333   \n",
       "4      Ahzab    1.0       5             2              0.400000   \n",
       "5      Krisi    1.0       5             2              0.400000   \n",
       "6     Amerah    1.0       6             3              0.500000   \n",
       "7  Mariellen    1.0       9             4              0.444444   \n",
       "8    Coriene    1.0       7             4              0.571429   \n",
       "9    Citalli    1.0       7             3              0.428571   \n",
       "\n",
       "   ends_with_vowels  0st_character  1st_character  2st_character  \\\n",
       "0                 1             -2             12             -2   \n",
       "1                 0            -12             -9              6   \n",
       "2                 1              9            -13             -2   \n",
       "3                 0            -13             -2            -10   \n",
       "4                 0            -13             -6             13   \n",
       "5                 1             -3              5             -5   \n",
       "6                 0            -13             -1             -9   \n",
       "7                 0             -1            -13              5   \n",
       "8                 1            -11              2              5   \n",
       "9                 1            -11             -5              7   \n",
       "\n",
       "   3st_character  ...  12st_character  13st_character  14st_character  \\\n",
       "0             -2  ...               0               0               0   \n",
       "1              6  ...               0               0               0   \n",
       "2             -5  ...               0               0               0   \n",
       "3             -5  ...               0               0               0   \n",
       "4            -13  ...               0               0               0   \n",
       "5              6  ...               0               0               0   \n",
       "6              5  ...               0               0               0   \n",
       "7             -5  ...               0               0               0   \n",
       "8             -5  ...               0               0               0   \n",
       "9            -13  ...               0               0               0   \n",
       "\n",
       "   15st_character  16st_character  17st_character  18st_character  \\\n",
       "0               0               0               0               0   \n",
       "1               0               0               0               0   \n",
       "2               0               0               0               0   \n",
       "3               0               0               0               0   \n",
       "4               0               0               0               0   \n",
       "5               0               0               0               0   \n",
       "6               0               0               0               0   \n",
       "7               0               0               0               0   \n",
       "8               0               0               0               0   \n",
       "9               0               0               0               0   \n",
       "\n",
       "   19st_character  20st_character  21st_character  \n",
       "0               0               0               0  \n",
       "1               0               0               0  \n",
       "2               0               0               0  \n",
       "3               0               0               0  \n",
       "4               0               0               0  \n",
       "5               0               0               0  \n",
       "6               0               0               0  \n",
       "7               0               0               0  \n",
       "8               0               0               0  \n",
       "9               0               0               0  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial = 'abcdefghijklm'\n",
    "final = 'nopqrstuvwxyz'\n",
    "dict_alpha = {}\n",
    "for i in (initial+final):\n",
    "  if i in initial:\n",
    "    dict_alpha[i] = float(ord(i) -96 -14)\n",
    "  if i in final:\n",
    "    dict_alpha[i] = float(ord(i) -96 -13)\n",
    "dict_alpha[\"'\"] = 0.0\n",
    "dict_alpha[\"-\"] = 0.0\n",
    "dict_alpha[\",\"] = 0.0\n",
    "dict_alpha[\" \"] = 0.0\n",
    "dict_alpha[\".\"] = 0.0\n",
    "dict_alpha[\"\\\\\"] = 0.0\n",
    "dict_alpha[\"/\"] = 0.0\n",
    "dict_alpha[\"(\"] = 0.0\n",
    "dict_alpha[\")\"] = 0.0\n",
    "dict_alpha[\"[\"] = 0.0\n",
    "dict_alpha[\"]\"] = 0.0\n",
    "dict_alpha[\"{\"] = 0.0\n",
    "dict_alpha[\"}\"] = 0.0\n",
    "\n",
    "for i in range(10):\n",
    "  dict_alpha[str(i)] = 0.0\n",
    "\n",
    "\n",
    "for i in range(22):\n",
    "  data[\"{}st_character\".format(i)] = 0\n",
    "\n",
    "for i, names in enumerate(data['Name']):\n",
    "  for j in range(maxLength):\n",
    "    if j < len(names):\n",
    "      data[\"{}st_character\".format(j)][i] = dict_alpha[names[j].lower()]\n",
    "    else:\n",
    "      data[\"{}st_character\".format(j)][i] = 0.0\n",
    "    \n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "y = data['Gender']\n",
    "data.drop(labels=\"Gender\", axis=1, inplace=True)\n",
    "data.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('Name', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X_train = data.values\n",
    "y_train = y\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "state = 12\n",
    "val_size = 0.2\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                 test_size=val_size,\n",
    "                                                 random_state=state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       67139.0284           55.10s\n",
      "         2       66887.4142           48.48s\n",
      "         3       66677.2315           43.55s\n",
      "         4       66417.1787           40.13s\n",
      "         5       66223.6334           38.06s\n",
      "         6       66038.9069           37.07s\n",
      "         7       65782.5269           36.95s\n",
      "         8       65521.7042           36.68s\n",
      "         9       65301.5884           35.87s\n",
      "        10       65075.9585           35.47s\n",
      "        20       63071.8875           32.11s\n",
      "        30       61143.6991           27.20s\n",
      "        40       59583.1488           22.96s\n",
      "        50       58190.9875           19.02s\n",
      "        60       56912.1416           15.57s\n",
      "        70       55901.0180           11.46s\n",
      "        80       54991.3527            7.59s\n",
      "        90       54174.6754            3.76s\n",
      "       100       53443.2648            0.00s\n",
      "Learning Rate 0.01\n",
      "Accuracy score (training):0.773\n",
      "Accuracy score (validation):0.768\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       66034.4584           55.03s\n",
      "         2       64892.4990           50.41s\n",
      "         3       63766.5702           46.33s\n",
      "         4       62760.1979           44.32s\n",
      "         5       61787.7013           43.59s\n",
      "         6       60984.1117           41.60s\n",
      "         7       60111.1232           40.92s\n",
      "         8       59455.9758           40.95s\n",
      "         9       58563.0107           39.65s\n",
      "        10       57989.9884           39.18s\n",
      "        20       53587.0056           32.74s\n",
      "        30       50852.9584           28.58s\n",
      "        40       49150.5078           23.56s\n",
      "        50       47934.6034           19.14s\n",
      "        60       46990.2211           15.16s\n",
      "        70       46203.8085           11.24s\n",
      "        80       45595.8697            7.40s\n",
      "        90       45002.3147            3.69s\n",
      "       100       44491.1513            0.00s\n",
      "Learning Rate 0.05\n",
      "Accuracy score (training):0.795\n",
      "Accuracy score (validation):0.789\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       64718.6803           36.47s\n",
      "         2       62680.9607           36.17s\n",
      "         3       60824.4740           35.51s\n",
      "         4       59376.2806           34.70s\n",
      "         5       58289.0569           34.15s\n",
      "         6       57057.6297           33.71s\n",
      "         7       55899.8911           33.60s\n",
      "         8       55053.8654           33.25s\n",
      "         9       54053.3221           33.34s\n",
      "        10       53316.2910           32.91s\n",
      "        20       49042.8887           30.03s\n",
      "        30       46856.4779           28.17s\n",
      "        40       45417.8560           23.87s\n",
      "        50       44349.7648           19.80s\n",
      "        60       43481.1004           15.32s\n",
      "        70       42730.6535           11.27s\n",
      "        80       42095.3282            7.35s\n",
      "        90       41524.5848            3.62s\n",
      "       100       40940.7671            0.00s\n",
      "Learning Rate 0.1\n",
      "Accuracy score (training):0.813\n",
      "Accuracy score (validation):0.807\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       57218.9614           34.06s\n",
      "         2       53976.8880           35.19s\n",
      "         3       51941.2045           36.50s\n",
      "         4       50408.9073           34.85s\n",
      "         5       49325.5770           33.45s\n",
      "         6       48467.4476           32.64s\n",
      "         7       47593.1222           32.22s\n",
      "         8       46986.4138           31.61s\n",
      "         9       46507.2078           31.18s\n",
      "        10       45999.3603           30.70s\n",
      "        20       42589.3628           27.29s\n",
      "        30       40999.3751           23.25s\n",
      "        40       39256.2893           19.86s\n",
      "        50       38643.9193           16.28s\n",
      "        60    65145007.4243           13.14s\n",
      "        70 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000            9.87s\n",
      "        80 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000            6.58s\n",
      "        90 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000            3.29s\n",
      "       100 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000            0.00s\n",
      "Learning Rate 0.5\n",
      "Accuracy score (training):0.847\n",
      "Accuracy score (validation):0.829\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       54960.1283           34.85s\n",
      "         2       51192.1144           35.87s\n",
      "         3       49142.6743           36.79s\n",
      "         4       47801.8677           35.71s\n",
      "         5       46190.5447           35.21s\n",
      "         6       45514.8856           33.92s\n",
      "         7       44921.0401           33.99s\n",
      "         8       44476.6769           33.31s\n",
      "         9       43816.4322           32.86s\n",
      "        10       43161.0629           33.04s\n",
      "        20       39844.0655           29.57s\n",
      "        30       37873.4280           24.88s\n",
      "        40       50258.5686           21.16s\n",
      "        50       49285.1505           17.48s\n",
      "        60 860904055908720476288952335024753036922078625792.0000           14.06s\n",
      "        70 860904055908720476288952335024753036922078625792.0000           10.52s\n",
      "        80 860904055908720476288952335024753036922078625792.0000            7.01s\n",
      "        90 5432096317808469708538474526150970326196574656397312.0000            3.43s\n",
      "       100 5432096317808293585829033024797810571761087510740992.0000            0.00s\n",
      "Learning Rate 0.75\n",
      "Accuracy score (training):0.853\n",
      "Accuracy score (validation):0.831\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       54219.4196           33.67s\n",
      "         2       54811.9688           33.77s\n",
      "         3       52899.0305           33.54s\n",
      "         4       51577.5990           34.49s\n",
      "         5       50791.0256           33.54s\n",
      "         6       50299.3149           32.78s\n",
      "         7       49712.4673           32.21s\n",
      "         8       49044.9298           32.03s\n",
      "         9       48450.1548           31.36s\n",
      "        10 270538335272418853371088371347682607169760321850734020140015202988196746890139205781917712515072.0000           31.21s\n",
      "        20 270538335272418853371088371347682607169760321850734020140015202988196746890139205781917712515072.0000           26.99s\n",
      "        30 83295834029725199026556405580545465790555685117898004216913633924213107549226103316830281317637469174637789184.0000           23.59s\n",
      "        40 83295834029725199026556405580545465790555685117898004216913633924213107549226103316830281317637469174637789184.0000           20.28s\n",
      "        50 83295834029725199026556405580545465790555685117898004216913633924213107549226103316830281317637469174637789184.0000           16.84s\n",
      "        60 4397062645319146499657975455151672466105743336762502088337450807653594118092911195126880129736571554093711549624483840.0000           13.45s\n",
      "        70 24146981580172200656658022046850714226672196255681239198170694980121661577587468361330424396282272225110365516013545224898112043419558739968.0000           10.12s\n",
      "        80 24146981580172200656658022046850714226672196255681239198170694980121661577587468361330424396282272225110365516013545224898112043419558739968.0000            6.85s\n",
      "        90 30330405698745368618788948381590432335291530265929240243691280751900829952932693536053680993843365882929056014412950397885493687505832116224.0000            3.52s\n",
      "       100 7862773095956755940534688573268282958868695674082407419694957609003356287006700712521060547801398180288242181812162365100053734453230212520900355424256.0000            0.00s\n",
      "Learning Rate 1\n",
      "Accuracy score (training):0.632\n",
      "Accuracy score (validation):0.626\n"
     ]
    }
   ],
   "source": [
    "lr_list = [0.01, 0.05, 0.1, 0.5, 0.75, 1]\n",
    "\n",
    "for learning_rate in lr_list:\n",
    "  gb_clf = GradientBoostingClassifier(n_estimators=100,\n",
    "                                     learning_rate=learning_rate,\n",
    "                                     max_features=5,\n",
    "                                     max_depth=5,\n",
    "                                     min_samples_split=28,\n",
    "                                     min_samples_leaf=10,\n",
    "                                     random_state=0,\n",
    "                                     verbose=1)\n",
    "  \n",
    "  gb_clf.fit(X_train, y_train)\n",
    "  \n",
    "  print(\"Learning Rate\", learning_rate)\n",
    "  print(\"Accuracy score (training):{0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "  print(\"Accuracy score (validation):{0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       57218.9614            7.17s\n",
      "         2       53976.8880            6.54s\n",
      "         3       51941.2045            6.21s\n",
      "         4       50408.9073            5.71s\n",
      "         5       49325.5770            5.24s\n",
      "         6       48467.4476            4.85s\n",
      "         7       47593.1222            4.56s\n",
      "         8       46986.4138            4.17s\n",
      "         9       46507.2078            3.79s\n",
      "        10       45999.3603            3.42s\n",
      "        20       42589.3628            0.00s\n",
      "Number of estimators 20\n",
      "Accuracy score (training):0.810\n",
      "Accuracy score (validation):0.803\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       57218.9614           16.76s\n",
      "         2       53976.8880           17.26s\n",
      "         3       51941.2045           16.95s\n",
      "         4       50408.9073           16.30s\n",
      "         5       49325.5770           16.08s\n",
      "         6       48467.4476           15.46s\n",
      "         7       47593.1222           15.98s\n",
      "         8       46986.4138           15.49s\n",
      "         9       46507.2078           14.97s\n",
      "        10       45999.3603           14.64s\n",
      "        20       42589.3628           10.80s\n",
      "        30       40999.3751            6.86s\n",
      "        40       39256.2893            3.35s\n",
      "        50       38643.9193            0.00s\n",
      "Number of estimators 50\n",
      "Accuracy score (training):0.835\n",
      "Accuracy score (validation):0.822\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       57218.9614           40.83s\n",
      "         2       53976.8880           41.08s\n",
      "         3       51941.2045           44.13s\n",
      "         4       50408.9073           41.73s\n",
      "         5       49325.5770           39.42s\n",
      "         6       48467.4476           37.48s\n",
      "         7       47593.1222           36.25s\n",
      "         8       46986.4138           35.31s\n",
      "         9       46507.2078           34.24s\n",
      "        10       45999.3603           33.34s\n",
      "        20       42589.3628           27.62s\n",
      "        30       40999.3751           23.97s\n",
      "        40       39256.2893           20.17s\n",
      "        50       38643.9193           16.90s\n",
      "        60    65145007.4243           13.45s\n",
      "        70 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000           10.08s\n",
      "        80 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000            6.62s\n",
      "        90 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000            3.28s\n",
      "       100 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000            0.00s\n",
      "Number of estimators 100\n",
      "Accuracy score (training):0.847\n",
      "Accuracy score (validation):0.829\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       57218.9614           50.38s\n",
      "         2       53976.8880           51.07s\n",
      "         3       51941.2045           52.73s\n",
      "         4       50408.9073           51.58s\n",
      "         5       49325.5770           52.81s\n",
      "         6       48467.4476           54.10s\n",
      "         7       47593.1222           54.46s\n",
      "         8       46986.4138           53.75s\n",
      "         9       46507.2078           52.80s\n",
      "        10       45999.3603           51.74s\n",
      "        20       42589.3628           45.66s\n",
      "        30       40999.3751           41.53s\n",
      "        40       39256.2893           38.42s\n",
      "        50       38643.9193           34.25s\n",
      "        60    65145007.4243           30.31s\n",
      "        70 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000           26.63s\n",
      "        80 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000           22.94s\n",
      "        90 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000           19.56s\n",
      "       100 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000           15.99s\n",
      "Number of estimators 150\n",
      "Accuracy score (training):0.841\n",
      "Accuracy score (validation):0.825\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       57218.9614            1.12m\n",
      "         2       53976.8880            1.12m\n",
      "         3       51941.2045            1.13m\n",
      "         4       50408.9073            1.11m\n",
      "         5       49325.5770            1.08m\n",
      "         6       48467.4476            1.07m\n",
      "         7       47593.1222            1.07m\n",
      "         8       46986.4138            1.06m\n",
      "         9       46507.2078            1.05m\n",
      "        10       45999.3603            1.04m\n",
      "        20       42589.3628           59.41s\n",
      "        30       40999.3751           56.84s\n",
      "        40       39256.2893           53.75s\n",
      "        50       38643.9193           50.95s\n",
      "        60    65145007.4243           47.47s\n",
      "        70 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000           43.59s\n",
      "        80 15075821453090719291660156837208819945448736689279551596342928936431067843135304818876438818121056256.0000           39.34s\n",
      "        90 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000           35.39s\n",
      "       100 8186312599284136596940136804188885256107762924710910874308154891433589389568543708595182948396476052862940638871552.0000           31.60s\n",
      "       200 191215621312266999134030405237246175124551465511367100901283124362827044634767106308942438163300280970124448552339405024280039234638895155026013282369536.0000            0.00s\n",
      "Number of estimators 200\n",
      "Accuracy score (training):0.833\n",
      "Accuracy score (validation):0.817\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "\n",
    "n_estimator_list = [20, 50, 100, 150, 200]\n",
    "\n",
    "for n_estimator in n_estimator_list:\n",
    "  gb_clf = GradientBoostingClassifier(n_estimators=n_estimator,\n",
    "                                     learning_rate=learning_rate,\n",
    "                                     max_features=5,\n",
    "                                     max_depth=5,\n",
    "                                     min_samples_split=28,\n",
    "                                     min_samples_leaf=10,\n",
    "                                     random_state=0,\n",
    "                                     verbose=1)\n",
    "  gb_clf.fit(X_train, y_train)\n",
    "  \n",
    "  print(\"Number of estimators\", n_estimator)\n",
    "  print(\"Accuracy score (training):{0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "  print(\"Accuracy score (validation):{0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       61020.3386            6.11s\n",
      "         2       60795.8928            5.72s\n",
      "         3       59651.8466            5.72s\n",
      "         4       59649.7541            5.06s\n",
      "         5       59184.4966            5.16s\n",
      "         6       59156.4969            4.87s\n",
      "         7       57245.3909            5.21s\n",
      "         8       57042.5022            5.08s\n",
      "         9       56890.9039            5.19s\n",
      "        10       55490.4964            5.27s\n",
      "        20       51001.0832            3.98s\n",
      "        30       48955.3028            2.62s\n",
      "        40       47500.7529            1.31s\n",
      "        50       45943.2702            0.00s\n",
      "Max features:  1\n",
      "Accuracy score (training):0.784\n",
      "Accuracy score (validation):0.778\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       57218.9614           17.15s\n",
      "         2       53976.8880           16.97s\n",
      "         3       51941.2045           16.73s\n",
      "         4       50408.9073           16.11s\n",
      "         5       49325.5770           15.47s\n",
      "         6       48467.4476           14.97s\n",
      "         7       47593.1222           14.65s\n",
      "         8       46986.4138           14.20s\n",
      "         9       46507.2078           13.73s\n",
      "        10       45999.3603           13.33s\n",
      "        20       42589.3628            9.76s\n",
      "        30       40999.3751            6.43s\n",
      "        40       39256.2893            3.25s\n",
      "        50       38643.9193            0.00s\n",
      "Max features:  5\n",
      "Accuracy score (training):0.835\n",
      "Accuracy score (validation):0.822\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       54157.2885           23.83s\n",
      "         2       50225.8769           24.43s\n",
      "         3       48233.9925           24.61s\n",
      "         4       46908.5829           24.32s\n",
      "         5       46198.3183           23.35s\n",
      "         6       45224.4256           22.59s\n",
      "         7       44757.2113           21.78s\n",
      "         8       44265.6129           20.98s\n",
      "         9       43668.1960           20.38s\n",
      "        10       43118.5244           20.09s\n",
      "        20       39834.9743           15.26s\n",
      "        30       37455.8233           10.35s\n",
      "        40       35719.4561            5.18s\n",
      "        50       34472.7026            0.00s\n",
      "Max features:  10\n",
      "Accuracy score (training):0.846\n",
      "Accuracy score (validation):0.831\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       54434.7375           44.41s\n",
      "         2       50817.6663           48.05s\n",
      "         3       48940.1717           46.92s\n",
      "         4 42593123386835928.0000           46.12s\n",
      "         5 42593123386834472.0000           44.59s\n",
      "         6 42593123386833616.0000           42.90s\n",
      "         7 42593123386388424.0000           41.10s\n",
      "         8 42593123386771792.0000           39.74s\n",
      "         9 42593123386771064.0000           38.98s\n",
      "        10 42593123386770352.0000           37.58s\n",
      "        20 30120078755278692024320.0000           27.80s\n",
      "        30 30120078755279065317376.0000           18.47s\n",
      "        40 26670686455398574002884404378183619505463281605205925477423775744.0000            8.97s\n",
      "        50 16208817755050004620617906473122119281594351580472865075416023364751799323865686866371859241199827671458930604624844166308823040.0000            0.00s\n",
      "Max features:  20\n",
      "Accuracy score (training):0.847\n",
      "Accuracy score (validation):0.830\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "n_estimator = 50\n",
    "max_feature_list = [1, 5, 10, 20]\n",
    "for max_feature in max_feature_list:\n",
    "  gb_clf = GradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                                    n_estimators=n_estimator,\n",
    "                                    max_features=max_feature,\n",
    "                                    max_depth=5,\n",
    "                                    min_samples_split=28,\n",
    "                                    min_samples_leaf=10,\n",
    "                                    verbose=1,\n",
    "                                    random_state=0)\n",
    "  gb_clf.fit(X_train, y_train)\n",
    "  \n",
    "  print(\"Max features: \", max_feature)\n",
    "  print(\"Accuracy score (training):{0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "  print(\"Accuracy score (validation):{0:.3f}\".format(gb_clf.score(X_val, y_val)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       60480.8224            8.96s\n",
      "         2       59671.1655            8.89s\n",
      "         3       58615.2497            8.07s\n",
      "         4       58087.4929            7.49s\n",
      "         5       57734.6050            6.97s\n",
      "         6       55967.1553            6.81s\n",
      "         7       54761.2466            6.54s\n",
      "         8       54378.0942            6.39s\n",
      "         9       53729.9664            6.14s\n",
      "        10       53489.0668            5.95s\n",
      "        20       51607.0201            4.21s\n",
      "        30       50734.9684            2.74s\n",
      "        40       50189.5373            1.35s\n",
      "        50       49809.5871            0.00s\n",
      "Max Depth:  1\n",
      "Accuracy score (training):0.760\n",
      "Accuracy score (validation):0.755\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       59073.3991           10.13s\n",
      "         2       56445.9392           10.42s\n",
      "         3       54947.6634            9.96s\n",
      "         4       54116.1566            9.87s\n",
      "         5       53544.9269            9.45s\n",
      "         6       52707.6037           10.20s\n",
      "         7       51974.0176           10.74s\n",
      "         8       51685.1964           10.92s\n",
      "         9       51138.9013           10.79s\n",
      "        10       50813.0499           10.23s\n",
      "        20       48580.2914            6.90s\n",
      "        30       47329.2449            4.41s\n",
      "        40       46301.5729            2.15s\n",
      "        50       45571.0631            0.00s\n",
      "Max Depth:  2\n",
      "Accuracy score (training):0.786\n",
      "Accuracy score (validation):0.782\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       55364.9195           19.60s\n",
      "         2       51990.6822           22.58s\n",
      "         3       50576.8064           21.50s\n",
      "         4       49425.3428           19.96s\n",
      "         5       48596.7391           19.09s\n",
      "         6       47901.0630           18.61s\n",
      "         7       47355.1519           18.62s\n",
      "         8       46851.1902           17.76s\n",
      "         9       46442.4464           17.22s\n",
      "        10       46054.8768           16.67s\n",
      "        20       42735.2345           11.92s\n",
      "        30       41986.9708            7.83s\n",
      "        40       40652.8227            3.87s\n",
      "        50       39487.2055            0.00s\n",
      "Max Depth:  4\n",
      "Accuracy score (training):0.828\n",
      "Accuracy score (validation):0.819\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       52321.4783            1.13m\n",
      "         2       46552.6087            1.27m\n",
      "         3       43624.2880            1.21m\n",
      "         4      139383.0613            1.16m\n",
      "         5      135204.7045            1.11m\n",
      "         6      134091.1515            1.08m\n",
      "         7      132973.8522            1.04m\n",
      "         8 6807112385289734403615807492487337897639388842711483936036999677782246216833480369285086838784.0000           59.19s\n",
      "         9 6807112385289734403615807492487337897639388842711483936036999677782246216833480369285086838784.0000           57.47s\n",
      "        10 6807112385289734403615807492487337897639388842711483936036999677782246216833480369285086838784.0000           55.98s\n",
      "        20 6807112385289734403615807492487337897639388842711483936036999677782246216833480369285086838784.0000           39.65s\n",
      "        30 6807112385289734403615807492487337897639388842711483936036999677782246216833480369285086838784.0000           26.16s\n",
      "        40 6807112385289734403615807492487337897639388842711483936036999677782246216833480369285086838784.0000           12.86s\n",
      "        50 6807112385289734403615807492487337897639388842711483936036999677782246216833480369285086838784.0000            0.00s\n",
      "Max Depth:  8\n",
      "Accuracy score (training):0.910\n",
      "Accuracy score (validation):0.858\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49397.2601            3.23m\n",
      "         2       41107.7395            3.23m\n",
      "         3       37347.2103            2.93m\n",
      "         4       33583.8537            2.92m\n",
      "         5       31473.3277            2.96m\n",
      "         6       29049.7975            3.00m\n",
      "         7       28049.6900            2.87m\n",
      "         8       26851.0751            2.74m\n",
      "         9       25048.2599            2.68m\n",
      "        10       23970.1173            2.64m\n",
      "        20       16439.9617            1.89m\n",
      "        30       12328.5081            1.21m\n",
      "        40        9245.0064           36.06s\n",
      "        50        6740.9541            0.00s\n",
      "Max Depth:  12\n",
      "Accuracy score (training):0.988\n",
      "Accuracy score (validation):0.871\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       47677.3442            5.49m\n",
      "         2       61170.8393            5.84m\n",
      "         3       55655.9287            5.68m\n",
      "         4      112183.3642            5.75m\n",
      "         5      111339.4433            5.85m\n",
      "         6      176766.9437            6.02m\n",
      "         7 152930712177.0448            5.91m\n",
      "         8 152930702811.2903            5.50m\n",
      "         9 152930698619.4263            5.24m\n",
      "        10 153878080426.9817            4.91m\n",
      "        20 12811871515200111417078906189346352147127745374642676007509688320.0000            3.05m\n",
      "        30 1084457457594275065001389814556220766800393566808317835750221180370351558114299067431385413909278557664385760700510082589203953695361712574278844547072.0000            1.63m\n",
      "        40 1084504203552360504974301040954074341584722349613705589295893624157998945443587190291682903479417037979182720211565680152098269524920307332061807509504.0000           40.08s\n",
      "        50 1084504238387869495876721338945167856844323985511176145766298924933144566026387508879419453899631651377570511680268547819191247170688361943319808311296.0000            0.00s\n",
      "Max Depth:  15\n",
      "Accuracy score (training):0.970\n",
      "Accuracy score (validation):0.854\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       45400.4178            7.60m\n",
      "         2       35172.1352            9.13m\n",
      "         3       29289.9780            8.99m\n",
      "         4       24380.5758            9.14m\n",
      "         5       24305.0099            8.92m\n",
      "         6       20751.1953            8.55m\n",
      "         7 351362832474005440.0000            8.15m\n",
      "         8 351362832342671488.0000            7.82m\n",
      "         9 351362832342603392.0000            7.45m\n",
      "        10 43587653779654290572347353012076554195607106390845481560223884125224133604679657916647863910459114710734473660583173263493351604224.0000            7.20m\n",
      "        20 43587653779654290572347353012076554195607106390845481560223884125224133604679657916647863910459114710734473660583173263493351604224.0000            4.64m\n",
      "        30 43587659535321194645385104154730510809893399169122400513737515053820872394730721735255343950924293192668206462931027818226361827328.0000            2.60m\n",
      "        40 78581947059427639750343814765374039705434984967114105585213142716056964109933484773794595296537318564387227538636142818191693849375410370845343744.0000            1.11m\n",
      "        50 3214884549571612967044015979543980640444138256695999353055062740696119016307272767512144909340995138426849520704936994772084226154610237841278492475392.0000            0.00s\n",
      "Max Depth:  20\n",
      "Accuracy score (training):0.954\n",
      "Accuracy score (validation):0.823\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "n_estimators = 50\n",
    "max_features = 10\n",
    "max_depth_list = [1, 2, 4, 8, 12, 15, 20]\n",
    "for max_depth in max_depth_list:\n",
    "  gb_clf = GradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                                     n_estimators=n_estimators,\n",
    "                                     max_features=max_features,\n",
    "                                     max_depth=max_depth,\n",
    "                                     min_samples_split=28,\n",
    "                                     min_samples_leaf=10,\n",
    "                                     random_state=0,\n",
    "                                     verbose=1)\n",
    "  gb_clf.fit(X_train, y_train)\n",
    "  \n",
    "  print(\"Max Depth: \", max_depth)\n",
    "  print(\"Accuracy score (training):{0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "  print(\"Accuracy score (validation):{0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       48976.4276            3.11m\n",
      "         2       42022.5720            3.17m\n",
      "         3       38623.8029            3.01m\n",
      "         4       35394.5859            3.26m\n",
      "         5       33754.6882            3.01m\n",
      "         6       31802.1630            3.02m\n",
      "         7       30541.4327            2.87m\n",
      "         8  1263633215.1423            2.80m\n",
      "         9  1263631156.3069            2.81m\n",
      "        10  1263630259.4576            2.64m\n",
      "        20 15571424557927436111583059837003253859826411898162938849972461728046381185609393537008238487681174535994867712.0000            1.82m\n",
      "        30 15571424557927436111583059837003253859826411898162938849972461728046381185609393537008238487681174535994867712.0000            1.12m\n",
      "        40 15571424557927436111583059837003253859826411898162938849972461728046381185609393537008238487681174535994867712.0000           30.76s\n",
      "        50 1035027389023033627685140178911369677919576793394015614052932760702173108163955588369705020367887255661417575359464667216871424.0000            0.00s\n",
      "Min Samples Split:  20\n",
      "Accuracy score (training):0.962\n",
      "Accuracy score (validation):0.861\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49158.8264            2.78m\n",
      "         2       41476.6967            3.02m\n",
      "         3      133738.5929            2.87m\n",
      "         4      164751.6657            3.05m\n",
      "         5      163172.7142            2.78m\n",
      "         6  5465399824.7519            2.60m\n",
      "         7  5465397094.9750            2.56m\n",
      "         8  5475335913.0420            2.48m\n",
      "         9  5475334265.0287            2.41m\n",
      "        10  5475333531.0692            2.29m\n",
      "        20 703517606220497101369901056.0000            1.62m\n",
      "        30 2153977294482337954144785737125453218051938923627764841832282593022787634524585984.0000            1.05m\n",
      "        40 2141939022996494696295640740948264840847175253316994814797480590474524092878824718526194909184.0000           30.05s\n",
      "        50 2173863034192229511443541288435430838627459914876299815302565024530856950267090304268612339596754727324402843648.0000            0.00s\n",
      "Min Samples Split:  25\n",
      "Accuracy score (training):0.973\n",
      "Accuracy score (validation):0.863\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49423.9779            2.76m\n",
      "         2       47454.1412            2.96m\n",
      "         3 4936188593128218531789503545772576349170435118353133836118786048.0000            2.98m\n",
      "         4 4936188593128218531789503545772576349170435118353133836118786048.0000            2.92m\n",
      "         5 5079947308131932055643572764361024057272706038539770918913179648.0000            2.76m\n",
      "         6 5079947308131932055643572764361024057272706038539770918913179648.0000            2.63m\n",
      "         7 5079947308131932055643572764361024057272706038539770918913179648.0000            2.54m\n",
      "         8 5079947308131932055643572764361024057272706038539770918913179648.0000            2.49m\n",
      "         9 5079957066964498361920912819514279349594984761985026543283339264.0000            2.46m\n",
      "        10 5079957066964498361920912819514279349594984761985026543283339264.0000            2.44m\n",
      "        20 6110844055670323776395348358781843743995987467922843334759269007360.0000            2.16m\n",
      "        30 6110844055670323776395348358781843743995987467922843334759269007360.0000            1.39m\n",
      "        40 16904793375007149545846322533519650588733837864024656362181444027463298242692428632154489365013814463234685549097619800487464302761615246229504.0000           37.42s\n",
      "        50 16904793009418647207311768481433366278532405579546313007517586213425281616798296096168783839862196629202456736771329128157856577781374644125696.0000            0.00s\n",
      "Min Samples Split:  30\n",
      "Accuracy score (training):0.974\n",
      "Accuracy score (validation):0.863\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49054.9290            2.65m\n",
      "         2       41436.4419            2.89m\n",
      "         3       37967.3723            2.78m\n",
      "         4       34210.1798            2.89m\n",
      "         5       32313.7923            2.72m\n",
      "         6 10804864727.1096            2.49m\n",
      "         7 142982671023547397255660099201707471458533376.0000            2.37m\n",
      "         8 474726837730290011666667524293338349702175784960.0000            2.32m\n",
      "         9 474726837730290011666667524293338349702175784960.0000            2.31m\n",
      "        10 474726837730290011666667524293338349702175784960.0000            2.30m\n",
      "        20 474726837730290011666667524293338349702175784960.0000            1.93m\n",
      "        30 3487162938956202943739515676100179530333164476776140364578816.0000            1.15m\n",
      "        40 3496988533773900167070827492312846584991591823761274642104320.0000           29.93s\n",
      "        50 3627206235483532630138967677906094628687662162764824606055299392914988212645258020100255187415871783655546524989915136.0000            0.00s\n",
      "Min Samples Split:  35\n",
      "Accuracy score (training):0.949\n",
      "Accuracy score (validation):0.863\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49055.6201            3.40m\n",
      "         2       47283.4186            3.37m\n",
      "         3       43454.5439            3.57m\n",
      "         4       39945.7739            3.54m\n",
      "         5       38512.3076            3.20m\n",
      "         6       36793.3217            2.97m\n",
      "         7       35512.2602            2.84m\n",
      "         8       33822.1087            2.76m\n",
      "         9       32891.6271            2.59m\n",
      "        10       31807.1415            2.54m\n",
      "        20       23685.2013            1.80m\n",
      "        30      909759.0598            1.18m\n",
      "        40 278630374631.3215           34.16s\n",
      "        50 68425367790873074962591469683270776026074497293247105819885097580264869662733800091274350505676485032918646784.0000            0.00s\n",
      "Min Samples Split:  40\n",
      "Accuracy score (training):0.978\n",
      "Accuracy score (validation):0.864\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "n_estimators = 50\n",
    "max_features = 10\n",
    "max_depth = 12\n",
    "min_samples_split_list = [20, 25, 30, 35, 40]\n",
    "\n",
    "for min_samples_split in min_samples_split_list:\n",
    "  gb_clf = GradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                                     n_estimators=n_estimators,\n",
    "                                     max_features=max_features,\n",
    "                                     max_depth=12,\n",
    "                                     min_samples_split=min_samples_split,\n",
    "                                     min_samples_leaf=10,\n",
    "                                     verbose=1,\n",
    "                                     random_state=0)\n",
    "  gb_clf.fit(X_train, y_train)\n",
    "  print(\"Min Samples Split: \", min_samples_split)\n",
    "  print(\"Accuracy score (training):{0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "  print(\"Accuracy score (validation):{0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49858.8550            3.32m\n",
      "         2       41754.8930            3.55m\n",
      "         3       39753.8347            3.18m\n",
      "         4       35995.5399            3.23m\n",
      "         5       34138.0336            3.08m\n",
      "         6       32411.2037            2.91m\n",
      "         7       30999.8974            2.74m\n",
      "         8       30672.0202            2.58m\n",
      "         9       29020.2489            2.51m\n",
      "        10       26595.9635            2.45m\n",
      "        20    16233446.2879            1.58m\n",
      "        30 2393394469187664985505129585378324021940949352448.0000           53.34s\n",
      "        40 8709706302598808933045546890491433562262144171315910591853647597137765497032480198555879458331613252599784316816427319296.0000           22.66s\n",
      "        50 5476379632136654711588703289819346021928488190922619620890332692949079967474642770977551901962356950729199515060343059740319884474086594556461056.0000            0.00s\n",
      "Min Samples Leaf:  5\n",
      "Accuracy score (training):0.945\n",
      "Accuracy score (validation):0.857\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49397.2601            2.56m\n",
      "         2       41107.7395            2.96m\n",
      "         3       37347.2103            2.79m\n",
      "         4       33583.8537            2.85m\n",
      "         5       31473.3277            2.71m\n",
      "         6       29049.7975            2.71m\n",
      "         7       28049.6900            2.55m\n",
      "         8       26851.0751            2.45m\n",
      "         9       25048.2599            2.46m\n",
      "        10       23970.1173            2.40m\n",
      "        20       16439.9617            1.69m\n",
      "        30       12328.5081            1.11m\n",
      "        40        9245.0064           32.83s\n",
      "        50        6740.9541            0.00s\n",
      "Min Samples Leaf:  10\n",
      "Accuracy score (training):0.988\n",
      "Accuracy score (validation):0.871\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49278.6909            2.85m\n",
      "         2       41424.7649            3.03m\n",
      "         3       37491.5870            2.88m\n",
      "         4       34366.5348            2.93m\n",
      "         5       32951.9742            2.68m\n",
      "         6       31005.8021            2.60m\n",
      "         7       29719.7144            2.46m\n",
      "         8       28168.7931            2.39m\n",
      "         9       26888.2923            2.34m\n",
      "        10       25840.3104            2.28m\n",
      "        20       26433.6032            1.63m\n",
      "        30       21455.9229            1.08m\n",
      "        40       18596.4575           32.42s\n",
      "        50       15857.8141            0.00s\n",
      "Min Samples Leaf:  15\n",
      "Accuracy score (training):0.982\n",
      "Accuracy score (validation):0.869\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49810.3066            2.41m\n",
      "         2       41943.0382            2.76m\n",
      "         3       37971.9399            2.62m\n",
      "         4       35362.5032            2.59m\n",
      "         5    11794555.6808            2.46m\n",
      "         6    11792832.0016            2.43m\n",
      "         7    11791558.7156            2.34m\n",
      "         8    11790310.3338            2.25m\n",
      "         9    11789259.2812            2.19m\n",
      "        10    11788353.9054            2.09m\n",
      "        20    11780774.0174            1.52m\n",
      "        30    11786589.9059           59.67s\n",
      "        40  2338708618.8463           29.56s\n",
      "        50 6976988285993508184128682576576512.0000            0.00s\n",
      "Min Samples Leaf:  20\n",
      "Accuracy score (training):0.975\n",
      "Accuracy score (validation):0.866\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49745.7474            2.71m\n",
      "         2       42227.9510            2.71m\n",
      "         3       38570.3905            2.58m\n",
      "         4       35553.9090            2.53m\n",
      "         5       34395.7628            2.31m\n",
      "         6       32158.2583            2.25m\n",
      "         7       31353.3604            2.13m\n",
      "         8       30375.3084            2.06m\n",
      "         9       29184.6590            2.04m\n",
      "        10       28151.6035            1.99m\n",
      "        20       21595.8598            1.33m\n",
      "        30       20313.7281           52.60s\n",
      "        40 8554503981066702022492568704341501713832837415596820564199604224.0000           25.90s\n",
      "        50 8554503981066702022492568704341501713832837415596820564199604224.0000            0.00s\n",
      "Min Samples Leaf:  25\n",
      "Accuracy score (training):0.965\n",
      "Accuracy score (validation):0.863\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "n_estimators = 50\n",
    "max_features = 10\n",
    "max_depth = 12\n",
    "min_samples_split = 28\n",
    "min_samples_leaf_list = [5, 10, 15, 20, 25]\n",
    "\n",
    "for min_samples_leaf in min_samples_leaf_list:\n",
    "  gb_clf = GradientBoostingClassifier(learning_rate=0.5,\n",
    "                                     n_estimators=50,\n",
    "                                     max_features=10,\n",
    "                                     max_depth=12,\n",
    "                                     min_samples_split=28,\n",
    "                                     min_samples_leaf=min_samples_leaf,\n",
    "                                     verbose=1,\n",
    "                                     random_state=0)\n",
    "  gb_clf.fit(X_train, y_train)\n",
    "  print(\"Min Samples Leaf: \", min_samples_leaf)\n",
    "  print(\"Accuracy score (training):{0:.3f}\".format(gb_clf.score(X_train, y_train)))\n",
    "  print(\"Accuracy score (validation):{0:.3f}\".format(gb_clf.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.5000000000000001, 'training_accuracy': 0.8731026880352751, 'validating_accuracy': 0.8731026880352751}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "learning_rate_list = np.arange(0.40, 0.60, 0.02)\n",
    "max_accuracy_validation = 0.000\n",
    "details = {\"learning_rate\":0.00, \"training_accuracy\": 0.000, \"validating_accuracy\": 0.000}\n",
    "for learning_rate in learning_rate_list:\n",
    "  gb_clf = GradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                                     n_estimators=50,\n",
    "                                     max_features=10,\n",
    "                                     max_depth=12,\n",
    "                                     min_samples_split=28,\n",
    "                                     min_samples_leaf=10,\n",
    "                                     verbose=0,\n",
    "                                     random_state=0)\n",
    "  gb_clf.fit(X_train, y_train)\n",
    "  train_acc = gb_clf.score(X_val, y_val)\n",
    "  valid_acc = gb_clf.score(X_val, y_val)\n",
    "  if valid_acc >= max_accuracy_validation:\n",
    "    max_accuracy_validation = valid_acc\n",
    "    details['learning_rate'] = learning_rate\n",
    "    details['training_accuracy'] = train_acc\n",
    "    details['validating_accuracy'] = valid_acc\n",
    "  else:\n",
    "    pass\n",
    "  \n",
    "print(details)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1       49397.2601            2.43m\n",
      "         2       41107.7395            2.99m\n",
      "         3       37347.2103            2.81m\n",
      "         4       33583.8537            2.88m\n",
      "         5       31473.3277            2.77m\n",
      "         6       29049.7975            2.81m\n",
      "         7       28049.6900            2.68m\n",
      "         8       26851.0751            2.58m\n",
      "         9       25048.2599            2.55m\n",
      "        10       23970.1173            2.47m\n",
      "        20       16439.9617            1.82m\n",
      "        30       12328.5081            1.30m\n",
      "        40        9245.0064           38.47s\n",
      "        50        6740.9541            0.00s\n",
      "Accuracy score (training):0.988\n",
      "Accuracy score (validation):0.871\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.5\n",
    "n_estimators = 50\n",
    "max_features = 10\n",
    "max_depth = 12\n",
    "min_samples_split = 28\n",
    "min_samples_leaf = 10\n",
    "\n",
    "gb_clf_final = GradientBoostingClassifier(learning_rate=learning_rate,\n",
    "                                   n_estimators=n_estimators,\n",
    "                                   max_features=max_features,\n",
    "                                   max_depth=max_depth,\n",
    "                                   min_samples_split=min_samples_split,\n",
    "                                   min_samples_leaf=min_samples_leaf,\n",
    "                                   verbose=1,\n",
    "                                   random_state=0)\n",
    "\n",
    "gb_clf_final.fit(X_train, y_train)\n",
    "print(\"Accuracy score (training):{0:.3f}\".format(gb_clf_final.score(X_train, y_train)))\n",
    "print(\"Accuracy score (validation):{0:.3f}\".format(gb_clf_final.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "modelGenderClassification = r'C:\\Users\\Sagar Mishra\\jupyter notebooks\\genderClassification.sav'\n",
    "pickle.dump(gb_clf_final, open(modelGenderClassification, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8707283982023234\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(modelGenderClassification, 'rb'))\n",
    "result = loaded_model.score(X_val, y_val)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing with a different csvFile containing names and gender\n",
    "\n",
    "test_dataset = r'D:\\Datasets\\gender-names\\name_gender'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
